{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987c6577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/user/nvme1n/lee/miniconda3/envs/mmretinal/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from torchvision.transforms import ToPILImage\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import torch.fft as fft\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset import *\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from imageio import imsave\n",
    "from dataset.GDRBench import GDRBench\n",
    "from dataset.data_manager import get_pre_FundusAug, get_post_FundusAug\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "    \n",
    "    \n",
    "class PatchMaskGenerator:\n",
    "    def __init__(self, ratio: float = 0.3) -> None:\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def transform(self, image: Image.Image) -> Image.Image:\n",
    "        # Get the height and width of the image\n",
    "        width, height = image.size\n",
    "\n",
    "        # Compute the patch size\n",
    "        patch_size = 16\n",
    "        while height % patch_size != 0 or width % patch_size != 0:\n",
    "            patch_size -= 1\n",
    "\n",
    "        # Compute the number of patches\n",
    "        num_patches = (height * width) // (patch_size * patch_size)\n",
    "\n",
    "        # Compute the number of patches to mask\n",
    "        mask_patches = int(np.ceil(num_patches * self.ratio))\n",
    "\n",
    "        # Create a mask of ones\n",
    "        mask = Image.new(\"L\", (width, height), color=255)\n",
    "        draw = ImageDraw.Draw(mask)\n",
    "\n",
    "        # Randomly select patches to mask\n",
    "        mask_patch_indices = random.sample(range(num_patches), mask_patches)\n",
    "        \n",
    "        for index in mask_patch_indices:\n",
    "            start_y = (index // (width // patch_size)) * patch_size\n",
    "            start_x = (index % (width // patch_size)) * patch_size\n",
    "            draw.rectangle([start_x, start_y, start_x + patch_size, start_y + patch_size], fill=0)\n",
    "\n",
    "        # Convert both image and mask to numpy arrays\n",
    "        image_np = np.array(image)\n",
    "        mask_np = np.array(mask) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "        # If the image is a 3-channel image, repeat the mask for all channels\n",
    "        if len(image_np.shape) == 3:\n",
    "            mask_np = np.expand_dims(mask_np, axis=-1)\n",
    "            mask_np = np.repeat(mask_np, image_np.shape[-1], axis=-1)\n",
    "\n",
    "        # Apply the mask\n",
    "        masked_image_np = image_np * mask_np\n",
    "\n",
    "        # Convert the numpy array back to a PIL Image\n",
    "        masked_image = Image.fromarray(np.uint8(masked_image_np))\n",
    "\n",
    "        return masked_image\n",
    "\n",
    "class PixelMaskGenerator:\n",
    "    def __init__(self, ratio: float = 0.6) -> None:\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def transform(self, pil_image):\n",
    "        # Convert PIL image to numpy array\n",
    "        image = np.array(pil_image)\n",
    "\n",
    "        # Infer the height and width from the image\n",
    "        height, width, channels = image.shape\n",
    "        \n",
    "        pixel_count = height * width\n",
    "        mask_count = int(np.ceil(pixel_count * self.ratio))\n",
    "\n",
    "        # Generate random mask\n",
    "        mask_idx = np.random.permutation(pixel_count)[:mask_count]\n",
    "        mask = np.ones(pixel_count, dtype=np.float32)  # Initialize mask as ones\n",
    "        mask[mask_idx] = 0  # Set selected indices to zero\n",
    "\n",
    "        mask = mask.reshape((height, width))\n",
    "\n",
    "        # Repeat the mask for all channels\n",
    "        mask = np.repeat(mask[:, :, np.newaxis], channels, axis=2)\n",
    "\n",
    "        masked_image = image * mask\n",
    "\n",
    "        # Convert numpy array back to PIL image\n",
    "        masked_pil_image = Image.fromarray(np.uint8(masked_image))\n",
    "\n",
    "        return masked_pil_image\n",
    "\n",
    "class FrequencyMaskGenerator:\n",
    "    def __init__(self, ratio: float = 0.3, band: str = 'all') -> None:\n",
    "        self.ratio = ratio\n",
    "        self.band = band  # 'low', 'mid', 'high', 'all'\n",
    "\n",
    "    def transform(self, image: Image.Image) -> Image.Image:\n",
    "        image_array = np.array(image).astype(np.complex64)\n",
    "        \n",
    "        # Convert mask to 3 channels if needed\n",
    "        if len(image_array.shape) == 3:\n",
    "            image_array = image_array\n",
    "        else:\n",
    "            image_array = np.repeat(image_array[..., None], 3, axis=2)\n",
    "            \n",
    "        freq_image = np.fft.fftn(image_array, axes=(0, 1))\n",
    "\n",
    "        # print(image_array.shape)\n",
    "        \n",
    "\n",
    "            \n",
    "        # print(image_array.shape)\n",
    "        \n",
    "        height, width = image_array.shape[0],image_array.shape[1]\n",
    "\n",
    "        mask = self._create_balanced_mask(height, width)\n",
    "        # print(mask.shape)\n",
    "        self.masked_freq_image = freq_image * mask\n",
    "        masked_image_array = np.fft.ifftn(self.masked_freq_image, axes=(0, 1)).real\n",
    "        masked_image = Image.fromarray(masked_image_array.astype(np.uint8))\n",
    "        return masked_image\n",
    "\n",
    "    def _create_balanced_mask(self, height, width):\n",
    "        mask = np.ones((height, width, 3), dtype=np.complex64)\n",
    "\n",
    "        # Determine the region of the frequency domain to mask\n",
    "        if self.band == 'low':\n",
    "            y_start, y_end = 0, height // 4\n",
    "            x_start, x_end = 0, width // 4\n",
    "        elif self.band == 'mid':\n",
    "            y_start, y_end = height // 4, 3 * height // 4\n",
    "            x_start, x_end = width // 4, 3 * width // 4\n",
    "        elif self.band == 'high':\n",
    "            y_start, y_end = 3 * height // 4, height\n",
    "            x_start, x_end = 3 * width // 4, width\n",
    "        elif self.band == 'all':\n",
    "            y_start, y_end = 0, height\n",
    "            x_start, x_end = 0, width\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid band: {self.band}\")\n",
    "\n",
    "        num_frequencies = int(np.ceil((y_end - y_start) * (x_end - x_start) * self.ratio))\n",
    "        mask_frequencies_indices = np.random.permutation((y_end - y_start) * (x_end - x_start))[:num_frequencies]\n",
    "        y_indices = mask_frequencies_indices // (x_end - x_start) + y_start\n",
    "        x_indices = mask_frequencies_indices % (x_end - x_start) + x_start\n",
    "\n",
    "        mask[y_indices, x_indices, :] = 0\n",
    "        return mask\n",
    "\n",
    "def test_mask_generator(\n",
    "    mask_type='spectral',\n",
    "    ratio=0.13, \n",
    "    sample_size=20\n",
    "    ):\n",
    "\n",
    "    # Create a MaskGenerator\n",
    "    if mask_type == 'spectral':\n",
    "        mask_generator = FrequencyMaskGenerator(ratio=ratio, band='all')\n",
    "    elif mask_type == 'pixel':\n",
    "        mask_generator = PixelMaskGenerator(ratio=ratio)\n",
    "    elif mask_type == 'patch':\n",
    "        mask_generator = PatchMaskGenerator(ratio=ratio)\n",
    "    else:\n",
    "        mask_generator = None\n",
    "\n",
    "    # transform = transforms.Compose([\n",
    "    #     transforms.Lambda(lambda img: mask_generator.transform(img)),\n",
    "    #     # transforms.Resize(256),\n",
    "    #     # transforms.CenterCrop(224),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    # ])\n",
    "    from configs.defaults import _C as cfg_default\n",
    "    cfg = cfg_default.clone()\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Lambda(lambda img: mask_generator.transform(img)),\n",
    "        transforms.Resize(224),        \n",
    "        transforms.ColorJitter( brightness=cfg.TRANSFORM.COLORJITTER_B, \n",
    "                               contrast=cfg.TRANSFORM.COLORJITTER_C, \n",
    "                                saturation=cfg.TRANSFORM.COLORJITTER_S, \n",
    "                                hue=cfg.TRANSFORM.COLORJITTER_H),\n",
    "        # transforms.Lambda(lambda img: mask_generator.transform(img)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataset = GDRBench(root = '/home/user/Projects/Medical-Image/Ophthalmology/DGDR/GDRBench', source_domains= ['DEEPDR'], target_domains = 'DEEPDR',  mode = 'train', trans_basic=transform, trans_mask=transform)\n",
    "    \n",
    "    \n",
    "    # data = ForenSynths(image_path, transform=transform)\n",
    "    # data = Wang_CVPR20(image_path, transform=transform)\n",
    "    # dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
    "\n",
    "    # Access the first image and label directly\n",
    "    # image, _, _, _, _ = next(train_loader)\n",
    "    \n",
    "    \n",
    "\n",
    "            \n",
    "    for image, mask, label, domain, img_index in train_loader:\n",
    "\n",
    "    # image_to_save = image\n",
    "\n",
    "    # Convert the tensor image to NumPy and transpose if necessary\n",
    "        image_to_save = image\n",
    "        \n",
    "        # # print(image.shape)  # torch.Size([32, 3, 224, 224])\n",
    "        # image_to_save = image_to_save.numpy().transpose(2,0,1)\n",
    "\n",
    "        # # Clip the values to the range [0, 1] if the image is in float format\n",
    "        # if image_to_save.dtype == np.float32 or image_to_save.dtype == np.float64:\n",
    "        #     image_to_save = np.clip(image_to_save, 0, 1)\n",
    "\n",
    "        sample_path = f'./samples'\n",
    "        os.makedirs(sample_path, exist_ok=True)\n",
    "        \n",
    "        for i, image in enumerate(image):\n",
    "            # Move the image tensor to CUDA and save it with the index as the filename\n",
    "            image = image.to(\"cuda\")\n",
    "            # save_image(image, f\"output/visualize/{folder_name}/image_{i}.png\")\n",
    "        \n",
    "            save_image(image, f\"{sample_path}/image_{i}.png\")\n",
    "\n",
    "        # # Save the image using imageio's imsave\n",
    "        # imsave(f\"{sample_path}/masked_{mask_type}.jpg\", (image_to_save * 255).astype(np.uint8))\n",
    "\n",
    "        # imsave(f\"{sample_path}/masked_{mask_type}.jpg\", (image_to_save).astype(np.uint8))\n",
    "\n",
    "    # # Display and save the image\n",
    "    # plt.imshow(image_to_save)\n",
    "    # plt.axis('off')  # Optional, to turn off axes\n",
    "    # plt.savefig(f\"{sample_path}/masked_{mask_type}.jpg\")\n",
    "\n",
    "# Usage:\n",
    "# test_mask_generator(\n",
    "#     '/home/timm/chandler/Experiments/FakeDetection/samples/original', \n",
    "#     mask_type='patch', # spectral, pixel, patch\n",
    "#     ratio=0.3\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c80ed30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248dc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmretinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
